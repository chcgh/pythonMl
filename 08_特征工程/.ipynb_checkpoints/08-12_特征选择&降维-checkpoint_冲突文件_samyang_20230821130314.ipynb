{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold,SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0, 2, 0, 3],\n",
    "    [0, 1, 4, 3],\n",
    "    [0.1, 1, 1, 3],\n",
    "    [1, 2, 3, 1],\n",
    "    [2, 3, 4, 3]\n",
    "], dtype=np.float32)\n",
    "Y = np.array([1,2,1,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方差选择法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VarianceThreshold(threshold=0.6)\n",
      "各个特征属性的方差为:\n",
      "[0.6176 0.56   2.64   0.64  ]\n",
      "-----------------\n",
      "[[0.  0.  3. ]\n",
      " [0.  4.  3. ]\n",
      " [0.1 1.  3. ]\n",
      " [1.  3.  1. ]\n",
      " [2.  4.  3. ]]\n"
     ]
    }
   ],
   "source": [
    "# 基于方差选择最优的特征属性\n",
    "#方差小于阈值的列被删除\n",
    "variance = VarianceThreshold(threshold=0.6)\n",
    "print(variance)\n",
    "variance.fit(X)\n",
    "print(\"各个特征属性的方差为:\")\n",
    "print(variance.variances_)\n",
    "print('-----------------')\n",
    "print(variance.transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SelectKBest\n",
    "SelectKBest是scikit-learn库中的一个特征选择函数，用于从数据集中选择k个最佳特征。它可以根据给定的评价函数和得分，来选择和排名特征。\n",
    "\n",
    "SelectKBest可以用于以下两种情况：\n",
    "\n",
    "- 想要减少数据集的维度，仅使用最重要的特征。\n",
    "\n",
    "- 想要获得每个特征的重要程度排名，以便进一步分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相关系数法\n",
    "\n",
    "- F值：指特征和目标变量之间的关系是否显著，是一个统计指标。F值越大，表示特征和目标变量之间的相关性越强。\n",
    "- 相关系数：指特征和目标变量之间的线性关系的强度和方向，可以是正相关、负相关或无关。相关系数的取值范围为[-1,1]，绝对值越大，表示相关性越强，符号表示相关性的方向。\n",
    "\n",
    "F值和相关系数是两个不同的指标，F值反映特征和目标变量之间的关系是否显著，相关系数反映特征和目标变量之间的线性关系的强度和方向。在特征选择中，通常使用F值作为评价函数，选择与目标变量相关性较强的特征，或者使用相关系数作为评价指标，评价每个特征与目标变量之间的关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest(k=2, score_func=<function f_regression at 0x000001C7D78745E0>)\n",
      "------------\n",
      "[0.04736842 0.36       1.32       1.8       ]\n",
      "------------\n",
      "[[0. 3.]\n",
      " [4. 3.]\n",
      " [1. 3.]\n",
      " [3. 1.]\n",
      " [4. 3.]]\n"
     ]
    }
   ],
   "source": [
    "#相关系数最大的k列被保留\n",
    "sk1 = SelectKBest(f_regression, k=2) #评分函数是 f_regression，这个函数使用 F 检验来计算特征的相关性。\n",
    "sk1.fit(X,Y)\n",
    "print(sk1)\n",
    "print('------------')\n",
    "print(sk1.scores_)\n",
    "print('------------')\n",
    "print(sk1.transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卡方检验\n",
    "\n",
    "卡方检验用于度量特征和目标变量之间的关联性，可以应用于离散特征的选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest(k=2, score_func=<function chi2 at 0x000001C7D78744C0>)\n",
      "[0.07741936 0.16666667 1.68055556 0.46153846]\n",
      "[[0. 3.]\n",
      " [4. 3.]\n",
      " [1. 3.]\n",
      " [3. 1.]\n",
      " [4. 3.]]\n"
     ]
    }
   ],
   "source": [
    "# 使用chi2的时候要求特征属性的取值为非负数\n",
    "sk2 = SelectKBest(chi2, k=2)\n",
    "sk2.fit(X, Y)\n",
    "print(sk2)\n",
    "print(sk2.scores_)\n",
    "print(sk2.transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.2688434  -0.38911349]\n",
      " [-1.25507558 -1.78088569]\n",
      " [ 5.26064254 -0.49688862]\n",
      " [ 6.34385833  1.16134391]\n",
      " [-4.05800618  3.58297801]\n",
      " [-3.02257571 -2.07743411]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "X = np.array([\n",
    "    [-1, -1, 3, 1], \n",
    "    [-2, -1, 2, 4], \n",
    "    [-3, -2, 4, 5], \n",
    "    [1, 1, 5, 4], \n",
    "    [2, 1, 6, -5], \n",
    "    [3, 2, 1, 5]])\n",
    "y = np.array([1, 1, 2, 2, 0, 1])\n",
    "# n_components：给定降低到多少维度，不能大于min(n_features,n_class-1)\n",
    "clf = LinearDiscriminantAnalysis(n_components=2)\n",
    "clf.fit(X, y)\n",
    "print(clf.transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## PCA降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.525  1.725  3.325  1.125  1.825 12.775]\n",
      "[[ 0.02038178 -0.01698103 -0.01350052 -0.0149724   0.03184796 -0.99893718]\n",
      " [ 0.9024592   0.25030511 -0.31422084 -0.15092666 -0.03185873  0.01965141]\n",
      " [-0.08872116 -0.06952185 -0.06858116 -0.3074396  -0.94204108 -0.02512755]]\n",
      "[[-0.85553344  0.91881223  0.82088162]\n",
      " [ 0.91401291  0.81156973 -0.86944521]\n",
      " [-0.87509227 -0.86146306 -0.86144931]\n",
      " [ 0.8166128  -0.8689189   0.9100129 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "X2 = np.array([\n",
    "    [ 5.1,  3.5,  1.4,  0.2, 1, 23],\n",
    "    [ 4.9,  3. ,  1.4,  0.2, 2.3, 2.1],\n",
    "    [ -6.2,  0.4,  5.4,  2.3, 2, 23],\n",
    "    [ -5.9,  0. ,  5.1,  1.8, 2, 3]\n",
    "], dtype=np.float64)\n",
    "# n_components: 给定降低到多少维度\n",
    "#               小于1时，表示保留的维度的重要性的占比，比如0.9表示占比为90%\n",
    "#               大于1时，表示保留的维度，但是该值必须小于等于min(样本数目,特征数目)\n",
    "# whiten：是否做一个白化的操作，在PCA的基础上，对于特征属性是否做一个标准化\n",
    "pca = PCA(n_components=3,whiten=True)\n",
    "pca.fit(X2)\n",
    "print(pca.mean_)\n",
    "print(pca.components_)\n",
    "print(pca.transform(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
